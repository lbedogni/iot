\section{Our Architectural Proposal}
\label{sec:casestudy}
In this section we discuss the our proposal and how we intend to carry out the architectural design.
We also give a glimpse on the case studies for this scenario in order to show why would someone use open data integration for measurement tasks.
\\
Figure~\ref{arch} shows an architecture depicting several use cases.

\begin{figure*}[!t]
\centering
\includegraphics[width=1\textwidth]{img/Archit.eps} 
\caption{}
\label{arch}
\end{figure*}

In our proposed architecture we assume to have a decision middleware, called Orchestrator, which is capable to return a service record, or a data stream, given a set of parameters determined by the user's choice.
Such information is returned from one among the sources available, provided that the user specified his or her preference for ``reliable'' or ``unreliable'' data, which namely corresponds to official or user-defined respectively.
We also aim to have our own data cloud for both data streams and services which are not intended to be published as open data onto one of the sources mentioned.

As a case study, an user can run an application making use of different measurements, for instance outdoor temperature and the amount of fine dust or pollen in the air, in order to infer an environmental condition or to trigger some action.
For instance it would open automatically the window that is not facing the sun when it's too hot, but just if the pollen in the air is below a certain threshold, otherwise it turns on the air conditioning in order to avoid allergic reactions.
Such a case study could happen in several situations.
An user, for example, might be the owner of the temperature sensor, since it is cheap and easily configurable (``Sensor 3'' in the figure).
However, other sensors such as pollen sensors or fine dust sensors might be too expensive or rare to get, or simply not owned by the end user and therefore other users' measurements are needed, provided they are nearby enough (this is also why geolocalization is meant to be crucial).

Furthermore, different data sources might have a different update rate and a different ``reliability'', since they may belong to providers that are recognized as trustworthy or not.
This happens when such providers receive several positive feedbacks due to their estimated precision and update rate.
Furthermore, in the integration presented we used two user-driven platforms, however, we aim to integrate our architecture with reliable and official data, such as EPA for the United States environmental measurements.
Such measurements, since they are official, are considered to be reliable, however their slow update rate introduces a trade-off whenever an user must choose between a high reliability or a fast update rate.
Some applications indeed might require information at a finer granularity over time, for example when they want to detect instantaneous condition changes.
In such cases the user, choosing the update frequency at the expense of reliability, will necessarily use the data or the services provided by neighbors.
\\

Our proposed architecture aims not only to unify raw data streams and make them universally available, but also to make users able to share their service endpoint and to provide additional capabilities derived from both data aggregation and personal computational capabilities (``Service 2'' in the figure).
As a simple example, an user receiving temperature and humidity data might calculate the heat index and expose it as a service interface.
\\

Our proposal, given such a various set of use cases, provides the user with a wide variety of options regarding deployment and data retrieval.
This is really important since the user is not forced to stick to a particular approach and gives a great advantage in an era where heterogeneity affects not only data and protocols, but also solutions.